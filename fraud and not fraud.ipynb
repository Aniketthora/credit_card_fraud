{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D://creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.168375e-15</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>-1.379537e-15</td>\n",
       "      <td>2.074095e-15</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.487313e-15</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.213481e-16</td>\n",
       "      <td>-2.406331e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.654067e-16</td>\n",
       "      <td>-3.568593e-16</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>4.473266e-15</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>1.683437e-15</td>\n",
       "      <td>-3.660091e-16</td>\n",
       "      <td>-1.227390e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.82725143693798"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()[0]/len(df)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Class Distributions \\n (0: No Fraud || 1: Fraud)')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors=[\"Blue\", \"Red\"]\n",
    "sns.countplot('Class',data=df, palette=colors)\n",
    "plt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.783274</td>\n",
       "      <td>-0.994983</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.269825</td>\n",
       "      <td>-0.994983</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.983721</td>\n",
       "      <td>-0.994972</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.418291</td>\n",
       "      <td>-0.994972</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.670579</td>\n",
       "      <td>-0.994960</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   scaled_amount  scaled_time        V1        V2        V3        V4  \\\n",
       "0       1.783274    -0.994983 -1.359807 -0.072781  2.536347  1.378155   \n",
       "1      -0.269825    -0.994983  1.191857  0.266151  0.166480  0.448154   \n",
       "2       4.983721    -0.994972 -1.358354 -1.340163  1.773209  0.379780   \n",
       "3       1.418291    -0.994972 -0.966272 -0.185226  1.792993 -0.863291   \n",
       "4       0.670579    -0.994960 -1.158233  0.877737  1.548718  0.403034   \n",
       "\n",
       "         V5        V6        V7        V8  ...       V20       V21       V22  \\\n",
       "0 -0.338321  0.462388  0.239599  0.098698  ...  0.251412 -0.018307  0.277838   \n",
       "1  0.060018 -0.082361 -0.078803  0.085102  ... -0.069083 -0.225775 -0.638672   \n",
       "2 -0.503198  1.800499  0.791461  0.247676  ...  0.524980  0.247998  0.771679   \n",
       "3 -0.010309  1.247203  0.237609  0.377436  ... -0.208038 -0.108300  0.005274   \n",
       "4 -0.407193  0.095921  0.592941 -0.270533  ...  0.408542 -0.009431  0.798278   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  Class  \n",
       "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n",
       "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n",
       "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n",
       "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n",
       "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import  RobustScaler\n",
    "\n",
    "# RobustScaler is less prone to outliers.\n",
    "\n",
    "\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "df['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "df['scaled_time'] = rob_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n",
    "\n",
    "df.drop(['Time','Amount'], axis=1, inplace=True)\n",
    "scaled_amount = df['scaled_amount']\n",
    "scaled_time = df['scaled_time']\n",
    "df.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
    "df.insert(0, 'scaled_amount', scaled_amount)\n",
    "df.insert(1, 'scaled_time', scaled_time)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Class',axis=1)\n",
    "y=df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 30)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE WITH CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "original_Xtrain = X_train.values\n",
    "original_Xtest = X_test.values\n",
    "original_ytrain = y_train.values\n",
    "original_ytest = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.95203616        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.95460291        nan 0.95460566        nan]\n",
      "  category=UserWarning\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [0.94674683        nan        nan 0.94722496]\n",
      "  category=UserWarning\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.94312792        nan]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:614: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 444, in _check_solver\n",
      "    \"got %s penalty.\" % (solver, penalty))\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.94574112 0.9419436 ]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9759353946762053\n",
      "precision: 0.06189271062805811\n",
      "recall: 0.9086335605322947\n",
      "f1: 0.11585597919749935\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import  RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "sss = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "accuracy_lst = []\n",
    "precision_lst = []\n",
    "recall_lst = []\n",
    "f1_lst = []\n",
    "\n",
    "\n",
    "log_reg_sm = LogisticRegression()\n",
    "\n",
    "\n",
    "log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "rand_log_reg = RandomizedSearchCV(LogisticRegression(), log_reg_params, n_iter=4)\n",
    "\n",
    "\n",
    "for train, test in sss.split(original_Xtrain, original_ytrain):\n",
    "    pipeline = imbalanced_make_pipeline(SMOTE(sampling_strategy='minority'), rand_log_reg) # SMOTE happens during Cross Validation not before..\n",
    "    model = pipeline.fit(original_Xtrain[train], original_ytrain[train])\n",
    "    best_est = rand_log_reg.best_estimator_\n",
    "    prediction = best_est.predict(original_Xtrain[test])\n",
    "    \n",
    "    accuracy_lst.append(pipeline.score(original_Xtrain[test], original_ytrain[test]))\n",
    "    precision_lst.append(precision_score(original_ytrain[test], prediction))\n",
    "    recall_lst.append(recall_score(original_ytrain[test], prediction))\n",
    "    f1_lst.append(f1_score(original_ytrain[test], prediction))\n",
    "    \n",
    "print(\"accuracy: {}\".format(np.mean(accuracy_lst)))\n",
    "print(\"precision: {}\".format(np.mean(precision_lst)))\n",
    "print(\"recall: {}\".format(np.mean(recall_lst)))\n",
    "print(\"f1: {}\".format(np.mean(f1_lst)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Fraud       1.00      0.97      0.99     56864\n",
      "       Fraud       0.05      0.93      0.10        98\n",
      "\n",
      "    accuracy                           0.97     56962\n",
      "   macro avg       0.53      0.95      0.54     56962\n",
      "weighted avg       1.00      0.97      0.98     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = ['No Fraud', 'Fraud']\n",
    "smote_prediction = best_est.predict(original_Xtest)\n",
    "print(classification_report(original_ytest, smote_prediction, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPARISION OF UNDER AND OVER SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>-0.179976</td>\n",
       "      <td>-0.994079</td>\n",
       "      <td>-0.427191</td>\n",
       "      <td>0.745708</td>\n",
       "      <td>1.761811</td>\n",
       "      <td>-0.165130</td>\n",
       "      <td>0.058298</td>\n",
       "      <td>-0.213413</td>\n",
       "      <td>0.647323</td>\n",
       "      <td>0.073464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052828</td>\n",
       "      <td>-0.201681</td>\n",
       "      <td>-0.432070</td>\n",
       "      <td>0.013164</td>\n",
       "      <td>0.161606</td>\n",
       "      <td>-0.401310</td>\n",
       "      <td>0.047423</td>\n",
       "      <td>0.102549</td>\n",
       "      <td>-0.116571</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248296</th>\n",
       "      <td>-0.307413</td>\n",
       "      <td>0.812780</td>\n",
       "      <td>-0.613696</td>\n",
       "      <td>3.698772</td>\n",
       "      <td>-5.534941</td>\n",
       "      <td>5.620486</td>\n",
       "      <td>1.649263</td>\n",
       "      <td>-2.335145</td>\n",
       "      <td>-0.907188</td>\n",
       "      <td>0.706362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.354773</td>\n",
       "      <td>0.319261</td>\n",
       "      <td>-0.471379</td>\n",
       "      <td>-0.075890</td>\n",
       "      <td>-0.667909</td>\n",
       "      <td>-0.642848</td>\n",
       "      <td>0.070600</td>\n",
       "      <td>0.488410</td>\n",
       "      <td>0.292345</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>-0.027947</td>\n",
       "      <td>-0.993104</td>\n",
       "      <td>1.171439</td>\n",
       "      <td>0.474974</td>\n",
       "      <td>0.011761</td>\n",
       "      <td>1.264303</td>\n",
       "      <td>0.116234</td>\n",
       "      <td>-0.865986</td>\n",
       "      <td>0.554393</td>\n",
       "      <td>-0.276375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119439</td>\n",
       "      <td>0.070051</td>\n",
       "      <td>0.278843</td>\n",
       "      <td>-0.097491</td>\n",
       "      <td>0.426278</td>\n",
       "      <td>0.744938</td>\n",
       "      <td>-0.274728</td>\n",
       "      <td>0.008472</td>\n",
       "      <td>0.015492</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239501</th>\n",
       "      <td>3.007895</td>\n",
       "      <td>0.768888</td>\n",
       "      <td>-6.682832</td>\n",
       "      <td>-2.714268</td>\n",
       "      <td>-5.774530</td>\n",
       "      <td>1.449792</td>\n",
       "      <td>-0.661836</td>\n",
       "      <td>-1.148650</td>\n",
       "      <td>0.849686</td>\n",
       "      <td>0.433427</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.928527</td>\n",
       "      <td>0.220526</td>\n",
       "      <td>1.187013</td>\n",
       "      <td>0.335821</td>\n",
       "      <td>0.215683</td>\n",
       "      <td>0.803110</td>\n",
       "      <td>0.044033</td>\n",
       "      <td>-0.054988</td>\n",
       "      <td>0.082337</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143336</th>\n",
       "      <td>3.226717</td>\n",
       "      <td>0.006967</td>\n",
       "      <td>-6.713407</td>\n",
       "      <td>3.921104</td>\n",
       "      <td>-9.746678</td>\n",
       "      <td>5.148263</td>\n",
       "      <td>-5.151563</td>\n",
       "      <td>-2.099389</td>\n",
       "      <td>-5.937767</td>\n",
       "      <td>3.578780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135711</td>\n",
       "      <td>0.954272</td>\n",
       "      <td>-0.451086</td>\n",
       "      <td>0.127214</td>\n",
       "      <td>-0.339450</td>\n",
       "      <td>0.394096</td>\n",
       "      <td>1.075295</td>\n",
       "      <td>1.649906</td>\n",
       "      <td>-0.394905</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        scaled_amount  scaled_time        V1        V2        V3        V4  \\\n",
       "121         -0.179976    -0.994079 -0.427191  0.745708  1.761811 -0.165130   \n",
       "248296      -0.307413     0.812780 -0.613696  3.698772 -5.534941  5.620486   \n",
       "239         -0.027947    -0.993104  1.171439  0.474974  0.011761  1.264303   \n",
       "239501       3.007895     0.768888 -6.682832 -2.714268 -5.774530  1.449792   \n",
       "143336       3.226717     0.006967 -6.713407  3.921104 -9.746678  5.148263   \n",
       "\n",
       "              V5        V6        V7        V8  ...       V20       V21  \\\n",
       "121     0.058298 -0.213413  0.647323  0.073464  ...  0.052828 -0.201681   \n",
       "248296  1.649263 -2.335145 -0.907188  0.706362  ...  0.354773  0.319261   \n",
       "239     0.116234 -0.865986  0.554393 -0.276375  ... -0.119439  0.070051   \n",
       "239501 -0.661836 -1.148650  0.849686  0.433427  ... -1.928527  0.220526   \n",
       "143336 -5.151563 -2.099389 -5.937767  3.578780  ...  0.135711  0.954272   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "121    -0.432070  0.013164  0.161606 -0.401310  0.047423  0.102549 -0.116571   \n",
       "248296 -0.471379 -0.075890 -0.667909 -0.642848  0.070600  0.488410  0.292345   \n",
       "239     0.278843 -0.097491  0.426278  0.744938 -0.274728  0.008472  0.015492   \n",
       "239501  1.187013  0.335821  0.215683  0.803110  0.044033 -0.054988  0.082337   \n",
       "143336 -0.451086  0.127214 -0.339450  0.394096  1.075295  1.649906 -0.394905   \n",
       "\n",
       "        Class  \n",
       "121         0  \n",
       "248296      1  \n",
       "239         0  \n",
       "239501      1  \n",
       "143336      1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_df = df.loc[df['Class'] == 1]\n",
    "non_fraud_df = df.loc[df['Class'] == 0][:492]\n",
    "\n",
    "normal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n",
    "\n",
    "# Shuffle dataframe rows\n",
    "new_df = normal_distributed_df.sample(frac=1, random_state=42)\n",
    "\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of the Classes in the subsample dataset\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: Class, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\seaborn\\_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Distribution of the Classes in the subsample dataset')\n",
    "print(new_df['Class'].value_counts()/len(new_df))\n",
    "\n",
    "\n",
    "\n",
    "sns.countplot('Class', data=new_df, palette=colors)\n",
    "plt.title('Equally Distributed Classes', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_und = new_df.drop('Class', axis=1)\n",
    "y_und = new_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_und,X_test_und,y_train_und,y_test_und=train_test_split(X_und,y_und,test_size=0.2,random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = X_train_und.shape[1]\n",
    "\n",
    "undersample_model = Sequential([\n",
    "    Dense(n_inputs, input_shape=(n_inputs, ), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                992       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 1,988\n",
      "Trainable params: 1,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "undersample_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersample_model.compile(Adam(lr=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "26/26 [==============================] - 1s 10ms/step - loss: 1.0156 - accuracy: 0.5211 - val_loss: 0.3848 - val_accuracy: 0.8924\n",
      "Epoch 2/20\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3552 - accuracy: 0.8594 - val_loss: 0.2593 - val_accuracy: 0.9304\n",
      "Epoch 3/20\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.2388 - accuracy: 0.9351 - val_loss: 0.2073 - val_accuracy: 0.9304\n",
      "Epoch 4/20\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1750 - accuracy: 0.9520 - val_loss: 0.1786 - val_accuracy: 0.9367\n",
      "Epoch 5/20\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1261 - accuracy: 0.9537 - val_loss: 0.1614 - val_accuracy: 0.9367\n",
      "Epoch 6/20\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1027 - accuracy: 0.9650 - val_loss: 0.1474 - val_accuracy: 0.9430\n",
      "Epoch 7/20\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1047 - accuracy: 0.9509 - val_loss: 0.1408 - val_accuracy: 0.9430\n",
      "Epoch 8/20\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.1007 - accuracy: 0.9657 - val_loss: 0.1328 - val_accuracy: 0.9430\n",
      "Epoch 9/20\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0871 - accuracy: 0.9673 - val_loss: 0.1296 - val_accuracy: 0.9430\n",
      "Epoch 10/20\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.9737 - val_loss: 0.1209 - val_accuracy: 0.9494\n",
      "Epoch 11/20\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.9618 - val_loss: 0.1195 - val_accuracy: 0.9494\n",
      "Epoch 12/20\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.9673 - val_loss: 0.1181 - val_accuracy: 0.9494\n",
      "Epoch 13/20\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.9606 - val_loss: 0.1149 - val_accuracy: 0.9494\n",
      "Epoch 14/20\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0562 - accuracy: 0.9755 - val_loss: 0.1126 - val_accuracy: 0.9494\n",
      "Epoch 15/20\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0433 - accuracy: 0.9854 - val_loss: 0.1091 - val_accuracy: 0.9494\n",
      "Epoch 16/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0541 - accuracy: 0.9749 - val_loss: 0.1074 - val_accuracy: 0.9494\n",
      "Epoch 17/20\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0398 - accuracy: 0.9873 - val_loss: 0.1079 - val_accuracy: 0.9494\n",
      "Epoch 18/20\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0338 - accuracy: 0.9911 - val_loss: 0.1035 - val_accuracy: 0.9494\n",
      "Epoch 19/20\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0385 - accuracy: 0.9836 - val_loss: 0.0994 - val_accuracy: 0.9494\n",
      "Epoch 20/20\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0257 - accuracy: 0.9951 - val_loss: 0.1004 - val_accuracy: 0.9494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19f016b7308>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersample_model.fit(X_train_und, y_train_und, validation_split=0.2, batch_size=25, epochs=20, shuffle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersample_predictions = undersample_model.predict(original_Xtest, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "undersample_fraud_predictions = undersample_model.predict_classes(original_Xtest, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "undersample_cm = confusion_matrix(original_ytest, undersample_fraud_predictions)\n",
    "actual_cm = confusion_matrix(original_ytest, original_ytest)\n",
    "labels = ['No Fraud', 'Fraud']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44790, 12074],\n",
       "       [    5,    93]], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersample_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56864,     0],\n",
       "       [    0,    98]], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sm = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "# Xsm_train, ysm_train = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "\n",
    "# This will be the data were we are going to \n",
    "Xsm_train, ysm_train = sm.fit_resample(original_Xtrain, original_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((454902,), (454902, 30))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ysm_train.shape,Xsm_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = Xsm_train.shape[1]\n",
    "\n",
    "oversample_model = Sequential([\n",
    "    Dense(n_inputs, input_shape=(n_inputs, ), activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample_model.compile(Adam(lr=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1214/1214 - 2s - loss: 0.0805 - accuracy: 0.9709 - val_loss: 0.0310 - val_accuracy: 0.9914\n",
      "Epoch 2/20\n",
      "1214/1214 - 2s - loss: 0.0171 - accuracy: 0.9957 - val_loss: 0.0101 - val_accuracy: 0.9999\n",
      "Epoch 3/20\n",
      "1214/1214 - 1s - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.0111 - val_accuracy: 0.9989\n",
      "Epoch 4/20\n",
      "1214/1214 - 2s - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "1214/1214 - 1s - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.0039 - val_accuracy: 0.9998\n",
      "Epoch 6/20\n",
      "1214/1214 - 1s - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "1214/1214 - 1s - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0015 - val_accuracy: 0.9999\n",
      "Epoch 8/20\n",
      "1214/1214 - 2s - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "1214/1214 - 2s - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "1214/1214 - 1s - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0019 - val_accuracy: 0.9997\n",
      "Epoch 11/20\n",
      "1214/1214 - 2s - loss: 0.0023 - accuracy: 0.9995 - val_loss: 5.6474e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "1214/1214 - 2s - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0017 - val_accuracy: 0.9997\n",
      "Epoch 13/20\n",
      "1214/1214 - 2s - loss: 0.0022 - accuracy: 0.9995 - val_loss: 6.4963e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "1214/1214 - 2s - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
      "Epoch 15/20\n",
      "1214/1214 - 1s - loss: 0.0019 - accuracy: 0.9996 - val_loss: 4.8387e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "1214/1214 - 2s - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0014 - val_accuracy: 0.9999\n",
      "Epoch 17/20\n",
      "1214/1214 - 1s - loss: 0.0017 - accuracy: 0.9996 - val_loss: 3.0533e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "1214/1214 - 2s - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0013 - val_accuracy: 0.9999\n",
      "Epoch 19/20\n",
      "1214/1214 - 2s - loss: 0.0015 - accuracy: 0.9997 - val_loss: 3.8526e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "1214/1214 - 2s - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0014 - val_accuracy: 0.9998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19f16c663c8>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversample_model.fit(Xsm_train, ysm_train, validation_split=0.2, batch_size=300, epochs=20, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample_predictions = oversample_model.predict(original_Xtest, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tensorflow-keras\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "oversample_fraud_predictions = oversample_model.predict_classes(original_Xtest, batch_size=200, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample_smote = confusion_matrix(original_ytest, oversample_fraud_predictions)\n",
    "actual_cm = confusion_matrix(original_ytest, original_ytest)\n",
    "labels = ['No Fraud', 'Fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56819,    45],\n",
       "       [   16,    82]], dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversample_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56864,     0],\n",
       "       [    0,    98]], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
